{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 1: Initialize necessary libraries and import images in color and grayscale."
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import cv2 as cv\n",
                "from matplotlib import pyplot as plt\n",
                "import alignment_utils as au # Import our new module\n",
                "\n",
                "# Load images in color and grayscale\n",
                "img1_color = cv.imread('images/0_00985.jpg')\n",
                "img1_gray = cv.cvtColor(img1_color, cv.COLOR_BGR2GRAY)\n",
                "\n",
                "img2_color = cv.imread('images/1_00969.jpg')\n",
                "img2_gray = cv.cvtColor(img2_color, cv.COLOR_BGR2GRAY)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 2: Feature matching parameters and variable initialization."
            },
            "outputs": [],
            "source": [
                "# Feature matching parameters\n",
                "MATCH_METHOD = 'SIFT' # Can be 'SIFT' or 'ORB'\n",
                "MIN_MATCH_COUNT = 10\n",
                "LOWE_RATIO = 0.7\n",
                "\n",
                "# Variable initialization\n",
                "kp1, des1 = None, None\n",
                "kp2, des2 = None, None\n",
                "good_matches = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 3: Detection and Matching using alignment_utils."
            },
            "outputs": [],
            "source": [
                "kp1, des1, kp2, des2, good_matches = au.detect_and_match(\n",
                "    img1_gray, img2_gray, method=MATCH_METHOD, lowe_ratio=LOWE_RATIO\n",
                ")\n",
                "print(f\"Found {len(good_matches)} good matches using {MATCH_METHOD}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 4: Homography calculation using alignment_utils."
            },
            "outputs": [],
            "source": [
                "M, mask = au.compute_homography(kp1, kp2, good_matches, MIN_MATCH_COUNT)\n",
                "\n",
                "dst = None\n",
                "if M is not None:\n",
                "    # Calculate projection for visualization preparation\n",
                "    # We'll calculate strictly the display points here, metrics in next block\n",
                "    h, w = img1_gray.shape\n",
                "    pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
                "    dst = cv.perspectiveTransform(pts, M)\n",
                "else:\n",
                "    print(f\"Not enough matches are found - {len(good_matches)}/{MIN_MATCH_COUNT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 5: Area and overlap calculation using alignment_utils."
            },
            "outputs": [],
            "source": [
                "overlay_lines = []\n",
                "\n",
                "if M is not None:\n",
                "    metrics = au.calculate_projection_and_overlap(M, img1_gray.shape, img2_gray.shape)\n",
                "    \n",
                "    overlay_lines = [\n",
                "        f\"Projected area: {metrics['area_proj_px']:.1f}px^2\",\n",
                "        f\"Overlap (on-canvas): {metrics['inter_area_px']:.1f}px^2\",\n",
                "        f\"Overlap/img2: {metrics['rel_to_img2']*100:.2f}%\",\n",
                "        f\"Overlap/proj: {metrics['rel_on_canvas_of_proj']*100:.2f}%\",\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "description": "Block 6: Visualization of results using alignment_utils."
            },
            "outputs": [],
            "source": [
                "if dst is not None:\n",
                "    img_result, img_matches = au.visualize_results(\n",
                "        img1_color, kp1, img2_color, kp2, good_matches, \n",
                "        mask, dst, overlay_lines\n",
                "    )\n",
                "\n",
                "    # Display the result\n",
                "    plt.figure(figsize=(15, 10))\n",
                "    plt.imshow(cv.cvtColor(img_result, cv.COLOR_BGR2RGB))\n",
                "    plt.title('Area Detection Result')\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "    \n",
                "    plt.figure(figsize=(20, 10))\n",
                "    plt.imshow(cv.cvtColor(img_matches, cv.COLOR_BGR2RGB))\n",
                "    plt.title('Feature Matches (Inliers)')\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No valid transformation found to visualize.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}